{"cells":[{"cell_type":"code","source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import classification_report, confusion_matrix\n","from sklearn.model_selection import GridSearchCV\n","import numpy as np"],"metadata":{"id":"xCcHgTyEYU3O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1pdXqrETYY24","executionInfo":{"status":"ok","timestamp":1733259090722,"user_tz":-60,"elapsed":17492,"user":{"displayName":"Gonzalo Caceres","userId":"01178933759601003683"}},"outputId":"1fd393ba-a2a6-4ccd-f331-499d9dcf5f25"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# Cargar desde Google Drive\n","df_subset = pd.read_csv('/content/drive/My Drive/NLP/datos_procesados.csv')"],"metadata":{"id":"kxcX6LMPlLsD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[" Creamos etiquetas binarias basadas en los ratings, dividimos los datos en características y etiquetas, y separamos esos datos en conjuntos de entrenamiento y prueba, asegurando un equilibrio entre las clases."],"metadata":{"id":"Y-OHlDOQeEqN"}},{"cell_type":"code","source":["# Crear la columna de etiquetas basada en el rating\n","df_subset['label'] = (df_subset['rating'] >= 4).astype(int)\n","\n","# Dividir los datos en características (X) y etiquetas (y)\n","X = df_subset['processed_text']\n","y = df_subset['label']\n","\n","# Dividir en conjunto de entrenamiento y prueba\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n","\n","print(f\"Tamaño del conjunto de entrenamiento: {len(X_train)}\")\n","print(f\"Tamaño del conjunto de prueba: {len(X_test)}\")\n","print(f\"Distribución de clases en el conjunto de entrenamiento:\\n{y_train.value_counts(normalize=True)}\")\n","print(f\"Distribución de clases en el conjunto de prueba:\\n{y_test.value_counts(normalize=True)}\")"],"metadata":{"id":"DHjrmSkXrLKD","colab":{"base_uri":"https://localhost:8080/"},"outputId":"821f413c-503b-40d9-efcd-1c17a6d0a6b6","executionInfo":{"status":"ok","timestamp":1733259102588,"user_tz":-60,"elapsed":309,"user":{"displayName":"Gonzalo Caceres","userId":"01178933759601003683"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tamaño del conjunto de entrenamiento: 6391\n","Tamaño del conjunto de prueba: 1598\n","Distribución de clases en el conjunto de entrenamiento:\n","label\n","0    0.500235\n","1    0.499765\n","Name: proportion, dtype: float64\n","Distribución de clases en el conjunto de prueba:\n","label\n","0    0.5\n","1    0.5\n","Name: proportion, dtype: float64\n"]}]},{"cell_type":"markdown","source":["Realizaremos la vectorización del texto utilizando TF-IDF, limitando las características a las 8000 palabras más relevantes (reducir la dimensionalidad y prevenir sobreajuste), transformando los textos de entrenamiento y prueba en matrices numéricas adecuadas para el análisis. A continuación, inicializamos y entrenamos dos modelos de clasificación: Regresión Logística y Random Forest, utilizando los datos vectorizados. Luego, evaluamos el rendimiento de ambos modelos en el conjunto de prueba, generando informes de clasificación y matrices de confusión para cada uno. Finalmente, comparamos las predicciones de ambos modelos para determinar el grado de acuerdo entre ellos, proporcionando una visión sobre la consistencia y efectividad de las predicciones en la tarea de clasificación."],"metadata":{"id":"DbOY4f9sbW3T"}},{"cell_type":"code","source":["# Vectorización del texto usando TF-IDF\n","vectorizer = TfidfVectorizer(max_features=8000)\n","X_train_vectorized = vectorizer.fit_transform(X_train)\n","X_test_vectorized = vectorizer.transform(X_test)\n","\n","# Inicializar y entrenar el modelo de Regresión Logística\n","logistic_model = LogisticRegression( max_iter=1000, random_state=42)\n","logistic_model.fit(X_train_vectorized, y_train)\n","\n","# Inicializar y entrenar el modelo Random Forest\n","rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n","rf_model.fit(X_train_vectorized, y_train)\n","\n","# Función para evaluar y mostrar resultados\n","def evaluate_model(model, X_test, y_test, model_name):\n","    y_pred = model.predict(X_test)\n","    print(f\"\\nResultados para {model_name}:\")\n","    print(classification_report(y_test, y_pred))\n","    print(\"Matriz de Confusión:\")\n","    print(confusion_matrix(y_test, y_pred))\n","\n","# Evaluar ambos modelos\n","evaluate_model(logistic_model, X_test_vectorized, y_test, \"Regresión Logística\")\n","evaluate_model(rf_model, X_test_vectorized, y_test, \"Random Forest\")\n","\n","# Comparar las predicciones de ambos modelos\n","y_pred_logistic = logistic_model.predict(X_test_vectorized)\n","y_pred_rf = rf_model.predict(X_test_vectorized)\n","\n","print(\"\\nComparación de predicciones:\")\n","print(f\"Acuerdo entre modelos: {np.mean(y_pred_logistic == y_pred_rf):.2%}\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y4_PUm3rg0Ua","executionInfo":{"status":"ok","timestamp":1733261069582,"user_tz":-60,"elapsed":7498,"user":{"displayName":"Gonzalo Caceres","userId":"01178933759601003683"}},"outputId":"2c3b0126-9b44-460d-944a-98418fec16a5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Resultados para Regresión Logística:\n","              precision    recall  f1-score   support\n","\n","           0       0.85      0.84      0.85       799\n","           1       0.84      0.85      0.85       799\n","\n","    accuracy                           0.85      1598\n","   macro avg       0.85      0.85      0.85      1598\n","weighted avg       0.85      0.85      0.85      1598\n","\n","Matriz de Confusión:\n","[[673 126]\n"," [119 680]]\n","\n","Resultados para Random Forest:\n","              precision    recall  f1-score   support\n","\n","           0       0.82      0.80      0.81       799\n","           1       0.81      0.82      0.81       799\n","\n","    accuracy                           0.81      1598\n","   macro avg       0.81      0.81      0.81      1598\n","weighted avg       0.81      0.81      0.81      1598\n","\n","Matriz de Confusión:\n","[[642 157]\n"," [142 657]]\n","\n","Comparación de predicciones:\n","Acuerdo entre modelos: 89.61%\n"]}]},{"cell_type":"markdown","source":["Los resultados de la evaluación de los modelos de Regresión Logística y Random Forest muestran que la Regresión Logística supera al Random Forest en precisión (0.85 frente a 0.81), recall y F1-score (aproximadamente 0.85 frente a 0.81), indicando un mejor rendimiento en la clasificación de sentimientos. La matriz de confusión revela que la Regresión Logística comete menos errores de clasificación, con un acuerdo del 89.61% entre las predicciones de ambos modelos, lo que sugiere que ambos capturan patrones similares en los datos, aunque la Regresión Logística es preferible para esta tarea específica."],"metadata":{"id":"QucxkNzOgYO7"}}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}